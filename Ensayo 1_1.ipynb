{
  "metadata": {
    "language_info": {
      "name": ""
    },
    "kernelspec": {
      "name": "",
      "display_name": ""
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# La Evolución de la Inteligencia Artificial\nLa inteligencia artificial es un campo de estudio que busca comprender y construir entidades inteligentes. Existen diferentes enfoques en el campo de la IA. Por otro lado, están los enfoques centrados en la racionalidad, que se basan en un concepto ideal de inteligencia y buscan que los sistemas sean racionales en función de su conocimiento. La Prueba de Turing, propuesta por Alan Turing en 1950, es una prueba que se utiliza para evaluar la inteligencia de un sistema.\n\nPara superar esta prueba, un sistema de IA debe tener capacidades como procesamiento de lenguaje natural, representación del conocimiento, razonamiento automático y aprendizaje automático. Ambos campos se alimentan mutuamente, especialmente en las áreas de visión y lenguaje natural. El campo de la visión ha avanzado recientemente gracias a una propuesta integrada que tiene en cuenta la evidencia neurofisiológica y los modelos computacionales. El estudio de estas leyes de pensamiento fue el inicio de un campo llamado lógica.\n\nAdemás, el enfoque del agente racional se basa en la capacidad de representar conocimiento, razonar basándose en él, generar sentencias comprensibles en lenguaje natural y aprender del conocimiento del mundo. El primer algoritmo no trivial se considera el algoritmo Euclidiano para calcular el máximo común divisor. Este algoritmo fue desarrollado por el matemático persa al-Khowarazmi en el siglo IX. Además de este algoritmo, al-Khowarazmi también introdujo los números arábigos y el álgebra en Europa.\n\nEn 1900, David Hilbert presentó una lista de 23 problemas matemáticos que ocuparían a los matemáticos durante todo el siglo. En el último problema, Hilbert se preguntaba si existe un algoritmo que permita determinar la validez de cualquier proposición lógica en la que aparezcan números naturales. Mediante su teorema de incompletitud, demostró que en cualquier lenguaje que tuviera la capacidad suficiente para expresar las propiedades de los números naturales, existen aseveraciones verdaderas no decidibles en el sentido de que no es posible decidir su validez mediante ningún algoritmo. Alan Turing, por su parte, trató de caracterizar las funciones que sí eran susceptibles de ser calculadas.\n\nPropuso la máquina de Turing como un modelo de cálculo universal y demostró que existen algunas funciones que no se pueden calcular mediante esta máquina. Además, Turing también demostró que no es posible decidir en general si un programa dado producirá una respuesta a partir de unas entradas o si seguirá calculando indefinidamente. La teoría de la NP-completitud, propuesta por Steven Cook y Richard Karp, proporciona un método para reconocer problemas intratables. Estos investigadores demostraron la existencia de grandes clases de problemas de razonamiento y búsqueda combinatoria que son NP-completos.\n\nToda clase de problema a la que la clase de problemas NP-completos se pueda reducir será seguramente intratable. Esto contrasta con el optimismo inicial sobre la capacidad de los computadores para resolver problemas complejos, ya que existen problemas que crecen exponencialmente en complejidad y no pueden resolverse en un tiempo razonable. Los economistas han desarrollado herramientas y modelos, como la teoría de la decisión y la teoría de juegos, para abordar este tipo de problemas. Posteriormente, Léon Walras, Frank Ramsey, John von Neumann y Oskar Morgenstern contribuyeron al desarrollo de la teoría económica, incluyendo la formalización matemática de la utilidad y la teoría de juegos.\n\nHerbert Simon, uno de los primeros investigadores en el campo de la IA, ganó el premio Nobel en Economía en 1978 por su trabajo en el que mostró que los modelos basados en satisfacción proporcionaban una descripción mejor del comportamiento humano real. La neurociencia es el estudio del sistema neurológico, especialmente del cerebro. Aunque la forma exacta en que el cerebro genera el pensamiento sigue siendo un misterio, se ha observado durante miles de años que el cerebro está involucrado en los procesos de pensamiento. El estudio de la neurociencia ha demostrado que el cerebro está formado por células nerviosas llamadas neuronas y que existen áreas localizadas en el cerebro responsables de funciones cognitivas específicas.\n\nEl desarrollo de técnicas como el electroencefalograma y la resonancia magnética funcional ha permitido a los neurólogos obtener imágenes detalladas de la actividad cerebral y medir los procesos cognitivos en desarrollo. Aunque se han realizado avances significativos en el estudio de la economía, la investigación operativa y la neurociencia, todavía queda mucho por descubrir y comprender sobre estos procesos cognitivos. La conclusión planteada en el texto es que una colección de células simples puede generar razonamiento, acción y conciencia, lo que implica que los cerebros generan inteligencia. La única teoría alternativa es el misticismo, que sostiene que existe una esfera mística en la que las mentes operan fuera del control de la ciencia física.\n\nPor ejemplo, un cerebro humano promedio tiene 1.000 veces más neuronas que las puertas lógicas en la Unidad Central de Procesamiento de una computadora estándar. Aunque se predice que el número de puertas lógicas de la UCP se igualará al número de neuronas del cerebro alrededor del año 2020 según la ley de Moore, las diferencias en la capacidad de almacenamiento y en la velocidad de intercambio y paralelismo son significativas. Las neuronas son millones de veces más lentas que los circuitos de las computadoras, y las neuronas y las sinapsis del cerebro están activas simultáneamente, mientras que las computadoras actuales tienen una o como mucho varias UCP. A pesar de que las computadoras son más rápidas en términos de velocidad de intercambio, el cerebro sigue siendo mucho más rápido en términos de lo que puede hacer 1.\n\nEn cuanto a la psicología, la psicología científica se inició con los trabajos de Hermann von Helmholtz y Wilhelm Wundt. En 1879, Wundt abrió el primer laboratorio de psicología experimental en la Universidad de Leipzig. Wundt enfatizó la realización de experimentos controlados en los que los participantes realizaban tareas de percepción o asociación mientras reflexionaban sobre sus procesos mentales. El movimiento conductista, liderado por John Watson, rechazó cualquier teoría que involucrara procesos mentales y se centró en mediciones objetivas de percepciones y acciones resultantes.\n\nLa conceptualización del cerebro como un dispositivo de procesamiento de información, característica principal de la psicología cognitiva, se remonta a las obras de William James. Aunque el conductismo tuvo una influencia notable en la psicología desde aproximadamente 1920 hasta 1960, los modelos cognitivos emergieron con fuerza en la Unidad de Psicología Aplicada de Cambridge, dirigida por Frederic Bartlett. Después de la muerte de Craik en un accidente de bicicleta en 1945, Donald Boadbent continuó su trabajo, y su libro «Perception and Communication» incluyó algunos de los primeros modelos de procesamiento de información del fenómeno psicológico. Mientras tanto, en Estados Unidos el desarrollo del modelo computacional llevó a la creación del campo de la ciencia cognitiva.\n\nSe puede decir que este campo comenzó en un simposio celebrado en el MIT, en septiembre de 1956. Estos tres artículos influyentes mostraron cómo se podían utilizar los modelos informáticos para modelar la psicología de la memoria, el lenguaje y el pensamiento lógico, respectivamente. Los psicólogos comparten en la actualidad el punto de vista común de que «la teoría cognitiva debe ser como un programa de computador» , o dicho de otra forma, debe describir un mecanismo de procesamiento de información detallado, lo cual lleva consigo la implementación de algunas funciones cognitivas. El computador ha sido el artefacto elegido.\n\nEl computador electrónico digital moderno se inventó de manera independiente y casi simultánea por científicos en tres países involucrados en la Segunda Guerra Mundial. El primer computador operacional programable fue el Z-3, inventado por Konrad Zuse en Alemania, en 1941. Zuse también inventó los números de coma flotante y el primer lenguaje de programación de alto nivel, Plankalkül. El primer computador electrónico, el ABC, fue creado por John Atanasoff junto a su discípulo Clifford Berry entre 1940 y 1942 en la Universidad Estatal de Iowa.\nLa percepción es fundamental para el funcionamiento de un agente, ya que su comportamiento se basa en las percepciones que recibe. Un agente racional es aquel que toma decisiones correctas, es decir, aquellas que le permiten obtener mejores resultados. Las medidas de rendimiento son los criterios que determinan el éxito en el comportamiento del agente, y pueden variar según el contexto y los objetivos específicos del agente, la utilización de medidas de rendimiento objetivas es importante en la inteligencia artificial para evaluar el desempeño de los agentes. Un agente racional maximiza su medida de rendimiento basándose en la información disponible hasta el momento. Sin embargo, es importante tener en cuenta que la racionalidad no garantiza la perfección y que la omnisciencia no es posible en la práctica, los agentes racionales deben recopilar información, aprender de la experiencia y ajustar su comportamiento en función de dicha información. No deben depender únicamente del conocimiento inicial proporcionado por sus diseñadores, sino que deben ser autónomos y adaptarse a las situaciones cambiantes, un agente racional debe ser autónomo y capaz de aprender a compensar el conocimiento inicial incompleto. La especificación completa del entorno de trabajo es esencial para el diseño de agentes racionales, ya que define las medidas de rendimiento, el entorno y los actuadores y sensores del agente. A medida que el agente adquiere experiencia e interactúa con el entorno, su comportamiento se vuelve independiente del conocimiento inicial y puede tener éxito en una variedad de entornos.\nLos entornos de trabajo en los que se utilizan técnicas de IA son muy diversos, y se pueden categorizar en diferentes dimensiones. Estas dimensiones son importantes para determinar el diseño adecuado del agente y la utilización de las principales técnicas en su implementación.\nUn entorno de trabajo es totalmente observable si los sensores del agente le proporcionan acceso al estado completo del medio en cada momento. Por otro lado, un entorno de trabajo es parcialmente observable cuando los sensores del agente no proporcionan acceso al estado completo del medio. Por ejemplo, una agente aspiradora con un solo sensor de suciedad local no puede saber si hay suciedad en otras áreas. La distinción entre entornos deterministas y estocásticos se refiere a si el siguiente estado del medio está totalmente determinado por el estado actual y la acción ejecutada por el agente.\n\nEn un entorno totalmente observable y determinista, un agente no necesita preocuparse por la incertidumbre. Por lo tanto, es útil pensar en términos de entornos deterministas o estocásticos desde la perspectiva del agente . La distinción entre entornos episódicos y secuenciales se basa en cómo se divide la experiencia del agente. En un entorno episódico, la experiencia del agente se divide en episodios atómicos.\n\nCada episodio consiste en la percepción del agente y la realización de una única acción posterior. La distinción entre entornos estáticos y dinámicos se refiere a si el entorno puede cambiar mientras el agente está tomando decisiones. En un entorno estático, el agente no necesita estar pendiente de los cambios en el mundo mientras toma decisiones. Por otro lado, en un entorno dinámico, el entorno está constantemente solicitando al agente que tome decisiones.\n\nLos entornos estáticos son más fáciles de manejar porque el agente no necesita preocuparse por el paso del tiempo o los cambios en el entorno. En contraste, los entornos dinámicos requieren que el agente esté constantemente atento a los cambios y tome decisiones en consecuencia. Si el entorno no cambia con el tiempo pero el rendimiento del agente sí, se dice que el medio es semidinámico . La distinción entre entornos discretos y continuos se aplica al estado del medio, la forma en que se maneja el tiempo y las percepciones y acciones del agente.\n\nLa distinción también se aplica a las percepciones y acciones del agente. Agente individual vs. La distinción entre un agente individual y un sistema multiagente se refiere a si el entorno del agente involucra a otros agentes. Un agente individual opera en un entorno donde no hay otros agentes con los que interactuar.\n\nPor ejemplo, resolver un crucigrama por sí mismo es un entorno de agente individual. La clave está en identificar si el comportamiento de una entidad está mejor descrito por la maximización de una medida de rendimiento que depende del comportamiento de otro agente. Por ejemplo, en el ajedrez, el oponente intenta maximizar su medida de rendimiento, lo que a su vez minimiza la medida de rendimiento del agente.\nel funcionamiento interno de los agentes de IA implica el diseño de programas que reciben las percepciones actuales como entrada y generan acciones como salida. Estos programas se ejecutan en una arquitectura que proporciona los sensores y actuadores necesarios para interactuar con el entorno, para manejar la visibilidad parcial, los agentes de IA deben almacenar información de las partes del mundo que no pueden ver y mantener un estado interno que refleje al menos algunos de los aspectos no observables del estado actual. Esto implica codificar conocimiento sobre cómo evoluciona el mundo y cómo las acciones del agente afectan al mundo. Un agente que utiliza este modelo del mundo se denomina agente basado en modelos.\nel conocimiento sobre el estado actual del mundo no siempre es suficiente para tomar decisiones, y los agentes basados en objetivos utilizan información adicional sobre los objetivos deseados para seleccionar las acciones adecuadas. Aunque pueden parecer menos eficientes, son más flexibles y pueden adaptarse a cambios en las circunstancias y objetivos.\nel uso de metas por sí solas no es suficiente para generar comportamiento de alta calidad en la mayoría de los entornos. La función de utilidad proporciona una medida más general de eficiencia y felicidad, permitiendo al agente basado en objetivos tomar decisiones racionales en situaciones con objetivos conflictivos o incertidumbre. Además, los agentes basados en objetivos son más flexibles y pueden adaptarse fácilmente a cambios en las circunstancias o en los objetivos deseados, el enfoque de construir agentes que aprenden es considerado el método más adecuado para crear sistemas novedosos en el campo de la inteligencia artificial. El aprendizaje permite a los agentes adaptarse a entornos desconocidos y mejorar su desempeño a través de la adquisición de nuevos conocimientos.\nla posibilidad práctica de las \"máquinas pensantes\" ha estado presente durante aproximadamente 50 años, pero aún no se ha llegado a un consenso sobre cómo definir el pensamiento en el contexto de las máquinas. La IA se centra en la búsqueda de programas agentes eficientes en una arquitectura dada, y el Test de Turing ha sido propuesto como una forma de evaluar la capacidad de una máquina para comportarse de manera inteligente. Sin embargo, hasta ahora, ningún programa ha superado el criterio del 30% en el Test de Turing frente a jueces con conocimiento, Turing examinó objeciones a la posibilidad de máquinas inteligentes, como la incapacidad de realizar ciertas acciones humanas. Sin embargo, las computadoras han demostrado poder realizar muchas tareas humanas, como jugar ajedrez, diagnosticar enfermedades y predecir resultados. Aunque aún hay tareas en las que las computadoras no sobresalen, su capacidad es evidente. Además, ciertas cuestiones matemáticas están más allá del alcance de las máquinas. Cabe destacar que estas respuestas se basan en información proporcionada por resultados de búsqueda y no en conocimientos previos del modelo de lenguaje.\nEl teorema de la incompletitud de Gödel plantea limitaciones en los sistemas axiomáticos formales, pero no proporciona evidencia concluyente de que las máquinas sean mentalmente inferiores a los humanos. La capacidad de establecer la verdad de una sentencia no es la única medida de la inteligencia, y no hay pruebas de que los humanos estén exentos de las limitaciones que afectan a los sistemas formales.\nEn su crítica a la Inteligencia Artificial (IA), Alan Turing argumentó que el comportamiento humano es demasiado complejo para ser capturado mediante un simple conjunto de reglas, lo que limita la capacidad de los ordenadores para generar un comportamiento inteligente. Hubert Dreyfus respaldó esta postura y argumentó que los ordenadores no pueden realizar ciertas tareas que los seres humanos sí pueden hacer, debido a la falta de conocimiento contextual y comprensión holística. Dreyfus sugirió que los sistemas de razonamiento probabilístico, como las redes neuronales, son más adecuados para abordar la complejidad del comportamiento humano. Esta crítica ha llevado a explorar enfoques alternativos en el campo de la IA.\nEn el debate sobre si una máquina que pasa el Test de Turing realmente puede pensar, Turing aborda las objeciones sobre la falta de conciencia y fenomenología en las máquinas. Argumenta que la cuestión no está bien definida y cuestiona por qué deberíamos exigir un estándar más alto para las máquinas que para los humanos. Turing sostiene que, en lugar de discutir constantemente sobre la conciencia, es comúnmente aceptado que todos pensamos. Presenta un diálogo en el que una máquina inteligente demuestra su capacidad para componer un soneto, pero también muestra limitaciones en su comprensión emocional. Turing reconoce que la conciencia es un tema difícil, pero no considera que sea relevante para la práctica de la IA. Argumenta que lo que importa es el comportamiento inteligente de las máquinas, no si son consideradas reales o simuladas. Además, se mencionan ejemplos de artefactos en los que el comportamiento es importante para determinar su autenticidad, como la urea artificial y los edulcorantes artificiales, mientras que otros, como las flores artificiales o un Picasso artificial, no se consideran auténticos debido a su origen o proceso de creación. En resumen, Turing defiende que la IA se centra en crear programas que se comporten de manera inteligente, sin necesidad de abordar el problema de la conciencia.\nEl debate sobre la conciencia en las mentes artificiales plantea preguntas sobre la similitud entre la simulación por computadora de procesos mentales y los procesos mentales reales. Las teorías del funcionalismo y el naturalismo biológico ofrecen perspectivas diferentes sobre la naturaleza de los estados mentales. El problema mente-cuerpo cuestiona cómo se relacionan los estados y procesos mentales con los estados y procesos del cuerpo. El materialismo sostiene que los estados mentales son estados del cerebro, pero enfrenta desafíos como explicar la libertad de elección en una mente puramente física.\nEl segundo problema que se plantea tiene relación con el tema general de la conciencia y las cuestiones de entendimiento y autoconocimiento relacionadas, aunque no idénticas. Se pregunta por qué se siente algo cuando se tienen ciertos estados cerebrales, mientras que probablemente no se siente nada al tener otros estados físicos, como ser una roca. Para abordar estas cuestiones, se necesita una forma de hablar sobre los estados del cerebro en términos más abstractos que las configuraciones específicas de los átomos del cerebro en un momento dado. Se requiere una noción de tipos de estados cerebrales para determinar si dos estados cerebrales pertenecen al mismo tipo o a un tipo diferente.\nExisten diferentes opiniones sobre el significado de \"tipo\" en este contexto. Se debate si el reemplazo de los átomos de carbono en un cerebro afectaría su estado mental. Se examina la clase de estados mentales conocidos como actitudes proposicionales, que incluyen creencias, conocimientos, deseos y temores. Se plantea la pregunta de si las computadoras pueden tener estos estados intencionales. Se discute si los estados mentales son determinados únicamente dentro del cerebro o si también tienen una conexión necesaria con el mundo externo. Se presenta el experimento del \"cerebro en una cubeta\" para analizar esta cuestión. Se propone una distinción entre la visión del \"contenido extenso\" y la visión del \"contenido estrecho\" para resolver el dilema. También se introduce el concepto de \"qualia\" o experiencias intrínsecas y se discute cómo las diferencias en la percepción del color pueden afectar los estados mentales.\nEl experimento de la prótesis cerebral fue introducido por Clark Glymour a mediados de los años 70 y retocado posteriormente por John Searle, aunque se asocia más comúnmente al trabajo de Hans Moravec. El experimento plantea la posibilidad de sustituir gradualmente todas las neuronas del cerebro humano por mecanismos electrónicos y luego revertir el proceso para volver al estado biológico normal. El objetivo es comprender cómo esto afectaría el comportamiento externo y la experiencia interna del sujeto.\nSegún Moravec, un investigador y funcionalista en robótica, la consciencia no se vería afectada por este experimento. Por otro lado, Searle, un filósofo y naturalista biólogo, cree que la consciencia desaparecería. Searle argumenta que si las neuronas reales quedan suspendidas entre el momento en que se extraen y el tiempo en que se reemplazan en el cerebro, el sujeto no \"recordará\" las experiencias durante la operación. Sin embargo, Patricia Churchland señala que los argumentos funcionalistas pueden aplicarse a diferentes niveles de unidades funcionales, lo que implica que si se acepta que el cerebro de sustitución es consciente, también se debería creer que la consciencia se mantiene cuando se sustituye todo el cerebro por un circuito que hace corresponder la entrada con la salida mediante una tabla de búsqueda.\nSearle sostiene que el entendimiento no está en el hombre ni en el papel, y sugiere que la memorización no es suficiente para tener entendimiento. Él argumenta que los programas informáticos son entidades sintácticas y formales, mientras que las mentes tienen contenidos o semánticas mentales. Según Searle, la sintaxis por sí sola no es suficiente para la semántica, y los cerebros son los que originan las mentes. A partir de estos axiomas, Searle concluye que los programas no son suficientes para las mentes, lo que implica que un agente que ejecuta un programa no necesariamente es una mente. Además, Searle afirma que cualquier cerebro artificial tendría que duplicar los poderes causales de los cerebros humanos para producir fenómenos mentales.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}